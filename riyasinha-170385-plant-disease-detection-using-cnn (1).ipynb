{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Plant disease detection**\nStep by step explaination","metadata":{}},{"cell_type":"markdown","source":"Importing neccessary packages","metadata":{"_uuid":"1020827e241ac87ffdf8e0f8762a6885bdc28fbc"}},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-15T04:49:28.525388Z","iopub.execute_input":"2021-06-15T04:49:28.52579Z","iopub.status.idle":"2021-06-15T04:49:32.111139Z","shell.execute_reply.started":"2021-06-15T04:49:28.525726Z","shell.execute_reply":"2021-06-15T04:49:32.110312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 25\nINIT_LR = 1e-3\nBS = 32\ndefault_image_size = tuple((256, 256))\nimage_size = 0\ndirectory_root = '../input/plantdisease'\nwidth=256\nheight=256\ndepth=3","metadata":{"execution":{"iopub.status.busy":"2021-06-15T04:49:32.113323Z","iopub.execute_input":"2021-06-15T04:49:32.113723Z","iopub.status.idle":"2021-06-15T04:49:32.119656Z","shell.execute_reply.started":"2021-06-15T04:49:32.113645Z","shell.execute_reply":"2021-06-15T04:49:32.118355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function to convert images to array","metadata":{"_uuid":"2bf7ac0a0b805946f844a48e55d5281403e53f57"}},{"cell_type":"code","source":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","metadata":{"_uuid":"c9c3e60b13ace6c8f3e54336e12f9970fde438a3","execution":{"iopub.status.busy":"2021-06-15T04:49:32.121238Z","iopub.execute_input":"2021-06-15T04:49:32.12168Z","iopub.status.idle":"2021-06-15T04:49:32.132225Z","shell.execute_reply.started":"2021-06-15T04:49:32.121535Z","shell.execute_reply":"2021-06-15T04:49:32.131428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fetch images from directory\n\n\nload the dataset — images of diseased plants","metadata":{"_uuid":"24d42b87fad54a9556f78357ce673cc5152468c1"}},{"cell_type":"code","source":"image_list, label_list = [], []\ntry:\n    print(\"[INFO] Loading images ...\")\n    root_dir = listdir(directory_root)\n    for directory in root_dir :\n        # remove .DS_Store from list\n        if directory == \".DS_Store\" :\n            root_dir.remove(directory)\n\n    for plant_folder in root_dir :\n        plant_disease_folder_list = listdir(f\"{directory_root}/{plant_folder}\")\n        \n        for disease_folder in plant_disease_folder_list :\n            # remove .DS_Store from list\n            if disease_folder == \".DS_Store\" :\n                plant_disease_folder_list.remove(disease_folder)\n\n        for plant_disease_folder in plant_disease_folder_list:\n            print(f\"[INFO] Processing {plant_disease_folder} ...\")\n            plant_disease_image_list = listdir(f\"{directory_root}/{plant_folder}/{plant_disease_folder}/\")\n                \n            for single_plant_disease_image in plant_disease_image_list :\n                if single_plant_disease_image == \".DS_Store\" :\n                    plant_disease_image_list.remove(single_plant_disease_image)\n                    \n##I picked just 200 images from each folder.\n\n            for image in plant_disease_image_list[:200]:\n                image_directory = f\"{directory_root}/{plant_folder}/{plant_disease_folder}/{image}\"\n                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n                    image_list.append(convert_image_to_array(image_directory))\n                    \n                    ##convert image to array using the function declared above.\n                    \n                    label_list.append(plant_disease_folder)\n    print(\"[INFO] Image loading completed\")  \nexcept Exception as e:\n    print(f\"Error : {e}\")","metadata":{"_uuid":"bb8d4c343314028f52ae3c3a840478a834a16c95","execution":{"iopub.status.busy":"2021-06-15T04:49:32.133657Z","iopub.execute_input":"2021-06-15T04:49:32.133993Z","iopub.status.idle":"2021-06-15T04:49:56.926195Z","shell.execute_reply.started":"2021-06-15T04:49:32.133942Z","shell.execute_reply":"2021-06-15T04:49:56.924944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get Size of Processed Image","metadata":{"_uuid":"35c4b76d33e0263523e479657580104532f81d6e"}},{"cell_type":"code","source":"image_size = len(image_list)","metadata":{"_uuid":"6ee1ad9c422f112ec2862699b5c0f68b8d658123","execution":{"iopub.status.busy":"2021-06-15T04:49:56.929913Z","iopub.execute_input":"2021-06-15T04:49:56.930213Z","iopub.status.idle":"2021-06-15T04:49:56.936104Z","shell.execute_reply.started":"2021-06-15T04:49:56.930164Z","shell.execute_reply":"2021-06-15T04:49:56.934713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Transform Image Labels uisng Scikit LabelBinarizer","metadata":{"_uuid":"905b41b226f3fd82a88e67821eb42a07f24b31f7"}},{"cell_type":"code","source":"label_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\npickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nn_classes = len(label_binarizer.classes_)","metadata":{"_uuid":"904ff893fe14f5060dd9e7be2ccf96ec793597e5","execution":{"iopub.status.busy":"2021-06-15T04:49:56.938025Z","iopub.execute_input":"2021-06-15T04:49:56.938341Z","iopub.status.idle":"2021-06-15T04:49:56.959217Z","shell.execute_reply.started":"2021-06-15T04:49:56.938289Z","shell.execute_reply":"2021-06-15T04:49:56.958123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print the classes","metadata":{"_uuid":"f860c29a1d714f06d25e6a0c5bca94739e5d24cc"}},{"cell_type":"code","source":"print(label_binarizer.classes_)","metadata":{"_uuid":"0f876397c40c3c8aa09772a92fd60481fc9ba268","execution":{"iopub.status.busy":"2021-06-15T04:49:56.960681Z","iopub.execute_input":"2021-06-15T04:49:56.960965Z","iopub.status.idle":"2021-06-15T04:49:56.965514Z","shell.execute_reply.started":"2021-06-15T04:49:56.960918Z","shell.execute_reply":"2021-06-15T04:49:56.964899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **I further pre-process the input data by scaling the data points from [0, 255] (the minimum and maximum RGB values of the image) to the range [0, 1]**","metadata":{}},{"cell_type":"code","source":"np_image_list = np.array(image_list, dtype=np.float16) / 225.0","metadata":{"_uuid":"6cd9c977b3d164a5570a0c24fdd8624adb9d56b8","execution":{"iopub.status.busy":"2021-06-15T04:49:56.966548Z","iopub.execute_input":"2021-06-15T04:49:56.966803Z","iopub.status.idle":"2021-06-15T04:50:08.709361Z","shell.execute_reply.started":"2021-06-15T04:49:56.966767Z","shell.execute_reply":"2021-06-15T04:50:08.708626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting data into Train and Test. I performed a training/testing split on the data using 80% of the images for training and 20% for testing","metadata":{}},{"cell_type":"code","source":"print(\"[INFO] Spliting data to train, test\")\nx_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) ","metadata":{"_uuid":"9f4829560fdfa218cee18c1cfb2eb9452ef180e5","execution":{"iopub.status.busy":"2021-06-15T04:50:08.710518Z","iopub.execute_input":"2021-06-15T04:50:08.710936Z","iopub.status.idle":"2021-06-15T04:50:09.552738Z","shell.execute_reply.started":"2021-06-15T04:50:08.710895Z","shell.execute_reply":"2021-06-15T04:50:09.551707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" **I created an image generator object which performs random rotations, shifts, flips, crops, and sheers on our image dataset. This allows us to use a smaller dataset and still achieve high results.**","metadata":{}},{"cell_type":"code","source":"aug = ImageDataGenerator(\n    rotation_range=25, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, \n    zoom_range=0.2,horizontal_flip=True, \n    fill_mode=\"nearest\")","metadata":{"_uuid":"eec8afa64e676d52c814fc8e096955a60f13b6c5","execution":{"iopub.status.busy":"2021-06-15T04:50:09.554126Z","iopub.execute_input":"2021-06-15T04:50:09.554427Z","iopub.status.idle":"2021-06-15T04:50:09.559502Z","shell.execute_reply.started":"2021-06-15T04:50:09.554374Z","shell.execute_reply":"2021-06-15T04:50:09.558701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next I created my model. \n\nIn the model we are defaulting to “channel_last” architecture but also creating a switch for backends that support “channel_first” on the fourth line. Then I created the first CONV => RELU => POOL. Our CONV layer has 32 filters with a 3 x 3 kernel and RELU activation (Rectified Linear Unit). We apply batch normalization, max pooling, and 25% (0.25) dropout.\n\n\nDropout is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data. It is a very efficient way of performing model averaging with neural networks.\n\n\nNext I created two sets of (CONV => RELU) * 2 => POOL blocks. Then only one set of FC (Fully Connected Layer)=> RELU layers","metadata":{}},{"cell_type":"code","source":"model = Sequential()\ninputShape = (height, width, depth)\nchanDim = -1\nif K.image_data_format() == \"channels_first\":\n    inputShape = (depth, height, width)\n    chanDim = 1\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization(axis=chanDim))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(n_classes))\nmodel.add(Activation(\"softmax\"))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-06-15T04:50:09.560991Z","iopub.execute_input":"2021-06-15T04:50:09.561256Z","iopub.status.idle":"2021-06-15T04:50:10.418092Z","shell.execute_reply.started":"2021-06-15T04:50:09.561203Z","shell.execute_reply":"2021-06-15T04:50:10.416999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Summary","metadata":{"_uuid":"53b13c03e4cea6dc2453a84e254b806ebeed2d99"}},{"cell_type":"code","source":"model.summary()","metadata":{"_uuid":"1e1523a834fbf872940171fbdefb3dcce2b5f31b","execution":{"iopub.status.busy":"2021-06-15T04:50:10.41971Z","iopub.execute_input":"2021-06-15T04:50:10.420009Z","iopub.status.idle":"2021-06-15T04:50:10.432565Z","shell.execute_reply.started":"2021-06-15T04:50:10.419957Z","shell.execute_reply":"2021-06-15T04:50:10.429516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n# distribution\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n# train the network\nprint(\"[INFO] training network...\")","metadata":{"execution":{"iopub.status.busy":"2021-06-15T04:50:10.435021Z","iopub.execute_input":"2021-06-15T04:50:10.435366Z","iopub.status.idle":"2021-06-15T04:50:10.500856Z","shell.execute_reply.started":"2021-06-15T04:50:10.43531Z","shell.execute_reply":"2021-06-15T04:50:10.499922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This particular step took me about 6 hrs. to complete.\n","metadata":{}},{"cell_type":"code","source":"history = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) // BS,\n    epochs=EPOCHS, verbose=1\n    )","metadata":{"execution":{"iopub.status.busy":"2021-06-15T04:50:10.502475Z","iopub.execute_input":"2021-06-15T04:50:10.502874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nPlot the train and val curve","metadata":{}},{"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n#Train and validation accuracy\nplt.plot(epochs, acc, 'b', label='Training accurarcy')\nplt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\nplt.title('Training and Validation accurarcy')\nplt.legend()\n\nplt.figure()\n#Train and validation loss\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Accuracy","metadata":{}},{"cell_type":"code","source":"print(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {scores[1]*100}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save model using Pickle","metadata":{}},{"cell_type":"code","source":"# save the model to disk\nprint(\"[INFO] Saving model...\")\npickle.dump(model,open('cnn_model.pkl', 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predicting result","metadata":{}},{"cell_type":"code","source":"loaded_model = pickle.load(open('cnn_model.pkl', 'rb'))\n\nimage_dir=\"../input/plantdisease/PlantVillage/Potato___Late_blight/01270f5c-a44b-4da7-9398-289088c197ab___RS_LB 2517.JPG\"\n\nim=convert_image_to_array(image_dir)\nnp_image_li = np.array(im, dtype=np.float16) / 225.0\nnpp_image = np.expand_dims(np_image_li, axis=0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result=model.predict(npp_image)\nprint(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}